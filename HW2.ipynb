{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2 - Decision Trees, Bias-Variance trade-off, and Ensemble Methods\n",
    "## CSCI 4622 - Fall 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Name**: $<$insert name here$>$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is due on Canvas by **11:59PM on September 30th**.\n",
    "\n",
    "Submit only this Jupyter notebook to Canvas. Do not compress it using tar, rar, zip, etc.\n",
    "Your solutions to analysis questions should be done in Markdown directly below the associated question.\n",
    "\n",
    "Remember that you are encouraged to discuss the problems with your classmates and instructors,\n",
    "but **you must write all code and solutions on your own**, and list any people or sources consulted.\n",
    "The only exception to this rule is that you may copy code directly from your own solution to homework 1 or labs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3659f5f0797fc0bb51f082d74edb1e7f",
     "grade": false,
     "grade_id": "overview",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Overview \n",
    "\n",
    "Your task for this homework is to build a decision tree classifier from scratch. Of course, we provide some initial classes that you'll be editing.\n",
    "Since the other two problems will use the scikit-learn's DecisionTreeClassifier, your solution does not have to be efficient as long as it passes the sanity checks in a reasonable time (typically less than ~1min).\n",
    "\n",
    "The last problem requires a _weak learner_, so we'll use a decision tree that yields low performance. But with _Ensemble Methods_, we will be able to improve the performance by aggregating predictions from multiple weak learners.\n",
    "For the ensemble methods, we'll explore bagging, Random Forest, and boosting (AdaBoost).\n",
    "\n",
    "Any Machine Learning interview will almost certainly have a question or two about decision trees and how they're trained.\n",
    "So understanding the code and trying to implement everything on your own will be the best way to prepare for such interviews.\n",
    "\n",
    "Also remember, if your code is correct then the sanity checks should pass without any major issue.\n",
    "But if the sanity checks pass that does not necessarily imply your code is 100% correct.\n",
    "\n",
    "Happy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import helpers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 - Decision Trees [38 points + 4 pts]\n",
    "***\n",
    "The goal of this problem is to implement the core elements of the Decision Tree classifier.\n",
    "We do not expect a highly efficient implementation of the functions since we will be using the implementation from scikit-learn in later problems.\n",
    "\n",
    "We'll be testing our implementation on a simple toy dataset:\n",
    "\n",
    "|Age|Income|Single| Has Pets | College Degree|\n",
    "|:------:|:-----------:| :----------:| :----------:|:--:|\n",
    "|20| 37000| 1| 0|0|\n",
    "|32| 50000| 0| 0|0|\n",
    "|24| 46000| 1| 1|0|\n",
    "|28| 52000| 1| 1|1|\n",
    "|28| 28000| 0| 1|0|\n",
    "|22| 54000| 0| 1|1|\n",
    "|28| 50000| 0| 0|1|\n",
    "|26| 36000| 0| 0|1|\n",
    "|24| 45000| 1| 1|0|\n",
    "|33| 45000| 0| 0|1|\n",
    "|34| 50000| 1| 1|0|\n",
    "|29| 51000| 1| 0|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = np.array([[20, 37000, 1, 0],\n",
    "                     [32, 50000, 0, 0],\n",
    "                     [24, 46000, 1, 1],\n",
    "                     [28, 52000, 1, 1],\n",
    "                     [28, 28000, 0, 1],\n",
    "                     [22, 54000, 0, 1],\n",
    "                     [28, 50000, 0, 0],\n",
    "                     [26, 36000, 0, 0],\n",
    "                     [24, 45000, 1, 1],\n",
    "                     [33, 45000, 0, 0],\n",
    "                     [34, 50000, 1, 1],\n",
    "                     [29, 51000, 1, 0]])\n",
    "labels = np.array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Each leaf node (terminal node) in a decision tree has a label value assigned to it. The same label will be assigned to all samples that reach the leaf node during the prediction.\n",
    "\n",
    "**Q1.1** [5 pts] Complete `compute_label` to return the label that should be assigned to the leaf node based on training labels in `y`.\n",
    "If more than one label are possible, choose the one with the lowest value (e.g, if both `0` and `1` are possible, choose `0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3ca234ceb96ce6286dc925b27e967c4",
     "grade": true,
     "grade_id": "a11",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_label(node_labels):\n",
    "\n",
    "    # Workspace 1.1\n",
    "    # TODO: Return the label that should be assigned to the leaf node\n",
    "    # In case of multiple possible labels, choose the one with the lowest value\n",
    "    # Make no assumptions about the number of class labels\n",
    "    label = None\n",
    "    # BEGIN \n",
    "    # code here\n",
    "    # END\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide below the LeafNode implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    def __init__(self, node_labels):\n",
    "        \"\"\" Initialize the leaf node\n",
    "        Args:\n",
    "            y: 1-d array containing labels, of shape (num_points,)\n",
    "        \"\"\"\n",
    "        self.label = compute_label(node_labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_terminal():\n",
    "        return True\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.label * np.ones(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%run -i tests leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "The tree also contains _decision nodes_. They can either be parents of: leaf nodes, decision nodes, or a combination of the two.\n",
    "\n",
    "Each decision node has a left and a right child. A node is branched out (parent node) **when we can reduce the uncertainty** by splitting\n",
    "the training instances based on a certain threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll need to choose an uncertainty measure. For this problem, we will use _entropy_ (scikit uses gini by default).\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Entropy}(y) = - \\sum_{c}  p_c \\log_2(p_c)\n",
    "\\end{align}\n",
    "\n",
    "where $p_c$ is the probability of occurrence (ratio)  of class $c$ among the labels in $y$\n",
    "\n",
    "**Q1.2** [5 pts] Complete the function `entropy` that returns the entropy measure of labels in `y`.\n",
    "\n",
    "_Hint:We use the convention `0 * log(0) = 0`. Make sure you handle multi-class labels (not just binary)._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9334c44c87751f857cc1a3f2b1dac7fb",
     "grade": true,
     "grade_id": "a12",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y: 1-d array contains labels, of shape (num_points,)\n",
    "    Returns: float, entropy measure of the values in y\n",
    "    \"\"\"\n",
    "    entropy_value = 0\n",
    "    # Workspace 1.2\n",
    "    # TODO: Compute the entropy of the labels\n",
    "    # BEGIN \n",
    "    # code here\n",
    "    # END\n",
    "    return entropy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell, uncomment to run the tests\n",
    "%run -i tests entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "When we create a decision node, we decide to split our samples $T$ to two parts $T_L$ and $T_R$, and we want to compute how much this split reduces the uncertainty (entropy).\n",
    "\n",
    "**Q1.3** [3 pts] Using the uncertainty measure $\\mathcal{u}$, what is the expression of the expected uncertainty reduction if we split $T$ into $T_L, T_R$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "195ac5994119324d7ac5730a83a36710",
     "grade": true,
     "grade_id": "a13",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "% BEGIN\n",
    "\n",
    "% YOUR ANSWER HERE\n",
    "\n",
    "% END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: When we use the entropy as our uncertainty measure, the uncertainty reduction in this case is also called _information gain_.\n",
    "(reducing the entropy implies that the partitioning decision variable and the labels have a higher mutual information).\n",
    "\n",
    "**Q1.4** [5 pts] Complete the `uncertainty_reduction` function to return the reduction of the split using the entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bba2372233be9fe33fa6b45389509452",
     "grade": true,
     "grade_id": "a14",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def uncertainty_reduction(y, left_indices, right_indices):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y: all labels\n",
    "        left_indices: the indices of the elements of y that belong to the left child\n",
    "        right_indices: the indices of the elements of y that belong to the right child\n",
    "    Returns: uncertainty reduction of the split\n",
    "    \"\"\"\n",
    "    reduction = 0\n",
    "    # Workspace 1.4\n",
    "    # BEGIN \n",
    "    # code here\n",
    "    # END\n",
    "    return reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell, uncomment to run the tests\n",
    "%run -i tests reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We'll use `best_split` to look up for the feature and threshold that yields the partition with the best uncertainty reduction.\n",
    "\n",
    "- For each feature:\n",
    "    - Compute all possible thresholds (use `split_values`)\n",
    "    - For each threshold:\n",
    "        - Split to `(left_indices, right_indices)` based on the threshold\n",
    "        - Compute the uncertainty reduction of the split\n",
    "- Returns the feature and the threshold that yield the highest uncertainty reduction (and the reduction value)\n",
    "<br>\n",
    "\n",
    "**Q1.5** [6 pts] Complete `best_split`. In case there are multiple possible solutions, return the first one encountered.\n",
    " \n",
    " _Hint: `split_values` is provided as a helper function. It takes the feature column and returns the set of thresholds. Use print to display the behavior if still not clear_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00f9406bd236e69578731e5a73225940",
     "grade": true,
     "grade_id": "a15",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_values(feature_values):\n",
    "    \"\"\" Helper function to return the split values. if feature consists of the values f1 < f2 < f3 then\n",
    "    this returns [(f2 + f1)/2, (f3 + f2)/2]\n",
    "    Args:\n",
    "        feature_values: feature_values: 1-d array of shape (num_points)\n",
    "    Returns:  array of shape (max(m-1, 1),) where m is the number of unique values in feature_values\n",
    "    \"\"\"\n",
    "    unique_values = np.unique(feature_values)\n",
    "    if unique_values.shape[0] == 1:\n",
    "        return unique_values\n",
    "    return (unique_values[1:] + unique_values[:-1]) / 2\n",
    "\n",
    "\n",
    "def best_split(X, y):\n",
    "    \"\"\" Find the feature id, threshold, indices, and reduction for the best split\n",
    "    Args:\n",
    "        X: features array, shape (num_samples, num_features)\n",
    "        y: labels of instances in X, shape (num_samples)\n",
    "    Returns: the best split related information.\n",
    "    \"\"\"\n",
    "\n",
    "    best_feature_id, best_threshold, best_left_indices, best_right_indices = None, None, None, None\n",
    "    best_reduction = -np.inf\n",
    "\n",
    "    # Workspace 1.5\n",
    "    # TODO: Complete the function as detailed in the question and return description\n",
    "    # BEGIN \n",
    "    # code here\n",
    "    # END\n",
    "    return best_feature_id, best_threshold, best_left_indices, best_right_indices, best_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell, uncomment to run the tests\n",
    "# If you chose to not use split_values, then this test will likely fail\n",
    "%run -i tests split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `left_child` will take instance for which`feature_id` value is <= `feature_threshold`. We should construct our decision tree as such.\n",
    "We define the DecisionNode class below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cd53beecc3ea5376771c3a6ca719c36",
     "grade": true,
     "grade_id": "a110",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, feature_id, threshold, left_child, right_child):\n",
    "        self.feature_id = feature_id\n",
    "        self.threshold = threshold\n",
    "        self.left = left_child\n",
    "        self.right = right_child\n",
    "\n",
    "    @staticmethod\n",
    "    def is_terminal():\n",
    "        return False\n",
    "\n",
    "    def add_importance(self, importances, X, y):\n",
    "        # Workspace 1.10\n",
    "        # Bonsu question\n",
    "        # BEGIN \n",
    "        # code here\n",
    "        # END\n",
    "        return importances\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros((X.shape[0]))\n",
    "        left_indices = np.where(X[:, self.feature_id] <= self.threshold)[0]\n",
    "        right_indices = np.where(X[:, self.feature_id] > self.threshold)[0]\n",
    "        y_pred[left_indices] = self.left.predict(X[left_indices])\n",
    "        y_pred[right_indices] = self.right.predict(X[right_indices])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tackle the core of a decision tree. The tree is built in a recursive way. The recursion in `build_tree` works as follows:\n",
    "- Parameters: `min_samples_split`, `depth`\n",
    "- Inputs: `X`, `y`\n",
    "- Base case of the recursion, return a leaf node if either:\n",
    "    - `depth` is 0\n",
    "    - `y` contains less than `min_samples_split` elements\n",
    "    - There is no uncertainty reduction (reduction<=0 for all splits)\n",
    "- Recursion (there is a split with reduction > 0):\n",
    "    - create a decision node with left and right child nodes with `depth - 1`\n",
    "    - return the decision node\n",
    "\n",
    "The left child node will contain instances for which the feature with index `best_feature` is <= than\n",
    "`best_threshold` of the split. The right child takes the remaining instances.\n",
    "\n",
    "\n",
    "**Q1.6** [8 pts] Complete `build_tree` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64051ee78e1460ed1098c79aa5855e38",
     "grade": true,
     "grade_id": "a16",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_tree(X, y, depth=-1, min_samples_split=2):\n",
    "    if depth == 0 or len(y) < min_samples_split:\n",
    "        # we reached the maximum depth or we don't have more than the minimum number of samples in the leaf\n",
    "        tree = LeafNode(y)\n",
    "    else:\n",
    "        # Get the feature, threshold and information_gain of the best split\n",
    "        feature_id, threshold, left_indices, right_indices, reduction = best_split(X, y)\n",
    "        # reduction = 0 occurs when the labels have the same distribution in the child nodes\n",
    "        # which means that the entropy of the children is the same as the parent's so we don't need to split\n",
    "        # Workspace 1.6\n",
    "        # TODO: if needed, create the left and right child nodes with depth - 1, return the decision node\n",
    "        # BEGIN \n",
    "        # code here\n",
    "        # END\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.7** [2 pts] Complete the `score` method that returns the accuracy on the given data (you can use `sklearn.metrics`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "913558eaa33f516c3ec2aa4e68cbc5d5",
     "grade": true,
     "grade_id": "a17",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, max_depth=-1, min_samples_split=2):\n",
    "        \"\"\" Initialize the decision tree\n",
    "        Args:\n",
    "            max_depth: maximum depth of the tree\n",
    "            min_samples_split: minimum number of samples required for a split\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "        self.num_features = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: Training samples\n",
    "            y: training labels\n",
    "        Return:\n",
    "             trained decision tree\n",
    "        \"\"\"\n",
    "        self.tree = build_tree(X, y, self.max_depth, self.min_samples_split)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Loops through rows of X and predicts the labels one row at a time\n",
    "        \"\"\"\n",
    "        return self.tree.predict(X)\n",
    "\n",
    "    def feature_importance(self, X, y):\n",
    "        \"\"\" Compute the importance of each feature in the decision tree\n",
    "         Only relevant to the bonus question\n",
    "        \"\"\"\n",
    "        feat_importance = {k:0 for k in range(X.shape[1])}\n",
    "        if not self.tree.is_terminal():\n",
    "            self.tree.add_importance(feat_importance, X, y)\n",
    "        feat_importance = {k: v/sum(feat_importance.values()) for k,v in feat_importance.items()}\n",
    "        return feat_importance\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\" Return the mean accuracy on the given test data and labels.\n",
    "        Args:\n",
    "            X: Test samples, shape (num_points, num_features)\n",
    "            y: true labels for X, shape (num_points,)\n",
    "        Return:\n",
    "            mean accuracy\n",
    "        \"\"\"\n",
    "        accuracy = 0\n",
    "        # Workspace 1.7\n",
    "        # BEGIN \n",
    "        # code here\n",
    "        # END\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test cell, uncomment to run the tests\n",
    "# If you chose to not use split_values, then this test will likely fail\n",
    "%run -i tests build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Q1.8** [2 pts] Using `min_samples_split=2`, what is the minimum depth so that our `DecisionTree` fits perfectly our dataset `(features, labels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfa3f7cf4ab8036e2f324d622974f19d",
     "grade": true,
     "grade_id": "a18",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Workspace 1.8\n",
    "# To show that the minimum required depth is n, you can provide the accuracy for depth = (n-1) and depth = n\n",
    "# BEGIN \n",
    "# code here\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We provide an example below to display the structure of a decision tree.\n",
    "\n",
    "**Q1.9** (2pts) Edit it to show the tree for the required minimum depth found in 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf66a005a28c1900e44c00b2abc43123",
     "grade": true,
     "grade_id": "a19",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN \n",
    "tree = DecisionTree(max_depth=3, min_samples_split=2).fit(features, labels)\n",
    "helpers.print_tree(tree, [\"age\", \"income\", \"single\", \"has_pets\"])\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus\n",
    "Now we can be a bit more ambitious and compute the importance of each feature in our decision tree. The importance of feature $f$\n",
    "is the sum of the weighted uncertainty reduction of decision nodes that are split based on the feature $f$.\n",
    "\n",
    "The weighted uncertainty reduction of $node_i$ is the following:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{N_{\\text{node}_i}}{N_\\text{total}} \\times \\textrm{Reduction}({\\text{node}_i}),\n",
    "\\end{align}\n",
    "\n",
    "where $N$ is the total number of training samples, and $N_{\\text{node}_i}$ is the number of training samples that reach the decision node $node_i$.\n",
    "\n",
    "Since we scale the feature importances in `DecisionTree` to sum to 1, we don't have to divide by $N_\\text{total}$\n",
    "and we can simply use:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{weighted reduction}(\\text{node}_i) = N_{\\text{node}_i} \\times \\textrm{Reduction}({\\text{node}_i}),\n",
    "\\end{align}\n",
    "\n",
    "Practically, we use a dictionary `feat_importance` that maps feature indices to their importances.\n",
    "- Start with `feat_importance[f]=0` for all `f`\n",
    "- Start the recursion from the root node:\n",
    "    - Current node is split based on feature `i`\n",
    "    - add weighted uncertainty reduction to `feat_importance[i]`\n",
    "    - ask right and left child to do the same\n",
    "- Scale the values in `feat_importance` to sum to 1\n",
    "- return `feat_importance`\n",
    "\n",
    "\n",
    "**(Bonus)Q1.10** [4 pts] Complete `DecisionNode`'s `feature_importance`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment to test\n",
    "# %run -i tests importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem 2: Bias-Variance Trade-off [24pts]\n",
    "\n",
    "In this problem, we will use the DecisionTreeRegressor from scikit-learn as our predictor.\n",
    "The Decision Tree Regression is an extension of Decision Tree Classification and differs in the following ways:\n",
    "- Instead of entropy/gini we use standard deviation for the uncertainty measure\n",
    "- The assigned label of the leaf node is the average value of samples label.\n",
    "\n",
    "The dataset we're working with is as simple as it can get: $x\\in[-1,1]$ and the target value is:\n",
    "\n",
    "$$y = f(x) + \\epsilon$$\n",
    "where $\\epsilon \\sim N(0,\\sigma^2)$ and $f(x) =  \\mathrm{sign}(x).(1 - \\cos (6\\pi x)$)\n",
    "\n",
    "\n",
    "**Q2.1** [4pts] Complete `compute_y`, `compute_f`, and `sample_data` following the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a18a5b4bbebe6a1fb4c3cbca433cbd91",
     "grade": true,
     "grade_id": "a21",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_f(x):\n",
    "    f_x = None\n",
    "    # Workspace 2.1.a\n",
    "    # TODO: return f(x)\n",
    "    # BEGIN \n",
    "    # code here\n",
    "    # END\n",
    "    return f_x\n",
    "\n",
    "\n",
    "def compute_y(x, sigma):\n",
    "    \"\"\" Compute y given x\n",
    "    Args:\n",
    "        x: numpy array of shape (num_samples, )\n",
    "        sigma: the standard deviation of the white noise\n",
    "    Returns: numpy array of shape (num_samples,)\n",
    "    \"\"\"\n",
    "    y = None\n",
    "    # Workspace 2.1.b\n",
    "    # TODO: add the generator noise epsilon to f(x)\n",
    "    # BEGIN \n",
    "    # code here\n",
    "    # END\n",
    "    return y\n",
    "\n",
    "\n",
    "def sample_data(num_samples, sigma):\n",
    "    \"\"\" Generate x and y given the standard deviation\n",
    "    Args:\n",
    "        num_samples: number of samples to generate\n",
    "        sigma: float, non-negative\n",
    "    Returns:\n",
    "        tuple (x, y), where x and y have shape (num_samples,)\n",
    "    \"\"\"\n",
    "    x, y = None, None\n",
    "    # Workspace 2.1.c\n",
    "    # TODO: generate num_samples y for the provided standard deviation\n",
    "    # BEGIN \n",
    "    # code here\n",
    "    # END\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n = 50\n",
    "x_values, y_values = sample_data(n, sigma=.15)\n",
    "xplot = np.linspace(-1, 1, 200)\n",
    "fplot = compute_f(xplot)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14, 7))\n",
    "for i, p in enumerate([4, 10]):\n",
    "    reg = DecisionTreeRegressor(max_depth=p).fit(x_values[:, None], y_values)\n",
    "    ax[i].scatter(x_values, y_values, c=\"y\")\n",
    "    ax[i].plot(xplot, fplot, c=\"b\")\n",
    "    ax[i].plot(xplot, reg.predict(xplot[:, None]), c=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Our goal now will be to make a plot of the decomposition of the expected validation Mean Squared Error (MSE) into its constituent parts.\n",
    "\n",
    "Let's denote $\\hat{f}_p$ the regression tree of max depth $p$. Since the training data $\\mathcal{D}$ is sampled and is random, the learned predictor $\\hat{f}_p$ is also random (depends on $\\mathcal{D}$)\n",
    "\n",
    "Let $s_0 = (x_0, y_0)$ be a validation sample. We define the expected Squared Error (SE) on $s_0$as : $\\textrm{SE}(x_0, y_0) = \\textrm{E}_\\mathcal{D}\\left[\\left(y_0 - \\hat{f}_p(x_0) \\right)^2\\right] $\n",
    "\n",
    "**Q2.2** [5pts] Show that\n",
    "$$ \\textrm{SE}(x_0, y_0) = \\underbrace{\\left[~f(x_0) - \\textrm{E}_\\mathcal{D}[~\\hat{f}_p(x_0)~] \\right]^2}_{\\alpha(x_0)}\n",
    "+ \\underbrace{\\textrm{E}_\\mathcal{D}\\left[ \\left( ~ \\textrm{E}_\\mathcal{D}[~\\hat{f}_p(x_0)]-\\hat{f}_p(x_0)~\\right)^2\\right]}_{\\beta(x_0)} + \\textrm{Var}(\\epsilon) $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0aaec3788864accd5e408cafa970d44d",
     "grade": true,
     "grade_id": "a22",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "% BEGIN\n",
    "\n",
    "% YOUR ANSWER HERE\n",
    "\n",
    "% END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Q2.3** [2pts] What do we call the $\\alpha(x_0)$ and $\\beta(x_0)$ terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a69aa9bb2214aa03aae97b460de8063",
     "grade": true,
     "grade_id": "a23",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "% BEGIN\n",
    "\n",
    "% YOUR ANSWER HERE\n",
    "\n",
    "% END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to run simulations to estimate the average value $\\mathrm{E}_{x_0}\\left[\\alpha(x_0)\\right]$ and $\\mathrm{E}_{x_0}\\left[\\beta(x_0)\\right]$ using different decision tree regression models. We will then plot these estimates against the validation Mean Squared Error.\n",
    "\n",
    "\n",
    "**Q2.4** [5pts] Complete the functions `estimate_quantities` to estimate $\\alpha_(x_0), \\beta_(x_0)$ and $SE(x_0, y_0)$ on the validation samples $(x_0, y_0)$ given a list of draws of $\\hat{f}_p$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad4c06960dbd433c4f0fd3a443c6e319",
     "grade": true,
     "grade_id": "a24",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_quantities(models_list, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        models_list: list of fit DecisionTreeRegressor models\n",
    "        x_valid: numpy array of shape (num_samples,)\n",
    "        y_valid: numpy array of shape (num_samples,)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    alpha = y_valid * 0\n",
    "    beta = y_valid * 0\n",
    "    se = y_valid * 0\n",
    "    # Workspace 2.4\n",
    "    # BEGIN \n",
    "    # code here\n",
    "    # END\n",
    "\n",
    "    return alpha, beta, se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Complete the cell below to plot 2 figures:\n",
    "- The expected  $\\mathrm{E}_{x_0}\\left[\\alpha(x_0)\\right]$ and $\\mathrm{E}_{x_0}\\left[\\beta(x_0)\\right]$ versus the tree depth $p$\n",
    "- The sum $\\mathrm{E}_{x_0}\\left[\\alpha(x_0)\\right]$ + $\\mathrm{E}_{x_0}\\left[\\beta(x_0)\\right]$ and the MSE on the validation data versus $p$\n",
    "\n",
    "**Q2.5** [5pts] For each depth, train 10 DecisionTreeRegression models (each per training set draw in `training_sets`) and save their quantities `alpha, beta, se` in `depth_[alpha | beta | se]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aadf4d43877279841c6c68d3f2a87643",
     "grade": true,
     "grade_id": "a25",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigma = 1.0\n",
    "train_num_samples = 256\n",
    "valid_num_samples = 256\n",
    "x_valid, y_valid = sample_data(valid_num_samples, sigma=sigma)\n",
    "training_sets = [sample_data(train_num_samples, sigma=sigma) for _ in range(10)]\n",
    "\n",
    "depths = np.arange(1, 17)\n",
    "depth_alpha = np.empty((depths.shape[0], valid_num_samples))\n",
    "depth_beta = np.empty((depths.shape[0], valid_num_samples))\n",
    "depth_se = np.empty((depths.shape[0], valid_num_samples))\n",
    "\n",
    "for i, depth in enumerate(depths):\n",
    "    # Workspace 2.5\n",
    "    # BEGIN \n",
    "    # code here\n",
    "    # END\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14, 7))\n",
    "\n",
    "mean_alpha = np.mean(depth_alpha, axis=1)\n",
    "mean_beta = np.mean(depth_beta, axis=1)\n",
    "mse = np.mean(depth_se, axis=1)\n",
    "\n",
    "# plot on ax[0] and ax[1]\n",
    "# BEGIN \n",
    "# code here\n",
    "# END\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Q2.6** [3pts] Comment on the obtained plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b764e0ce4ab213b0689840900397aef",
     "grade": true,
     "grade_id": "a26",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "% BEGIN\n",
    "\n",
    "% YOUR ANSWER HERE\n",
    "\n",
    "% END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 - Decision Tree Ensembles [38 pts + 5pts]\n",
    "---\n",
    "\n",
    "\n",
    "In this problem, we will introduce 3 ensemble methods to _boost_ the performance of this poor and underestimated weak learner.\n",
    "\n",
    "First, we'll need a fancier dataset. We are going to predict house price levels using the decision trees.\n",
    "\n",
    "We start by loading preprocessed data that we'll use. Since the original House Prices [dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) is for regression, we have to transform `HousePrices.y` to discrete values reflecting price level.\n",
    "\n",
    "|Price range| Label|\n",
    "|:----------:|--:|\n",
    "| $ P < $125000|0|\n",
    "|125000$\\leq P < $ 160000| 1 |\n",
    "|160000$ \\leq P < $ 200000| 2 |\n",
    "|200000$ \\leq P $ | 3 |\n",
    "\n",
    "\n",
    "**Q3.1** [3pts] Transform `house_prices.y` following the table above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2b8cc230a1d4027811f81e91657c973",
     "grade": true,
     "grade_id": "a31",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import data\n",
    "\n",
    "house_prices = data.HousePrices()\n",
    "# Workspace 3.1\n",
    "# TODO: Discretize house_prices.y\n",
    "# BEGIN \n",
    "# code here\n",
    "# END\n",
    "print(np.unique(house_prices.y), house_prices.X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment to test\n",
    "#%run -i tests discretize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3, min_samples_leaf=0.1).fit(house_prices.X, house_prices.y)\n",
    "print(\"Accuracy on training set:\", tree.score(house_prices.X, house_prices.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above show that even when evaluated on the training data, a decision tree of depth 3 does not perform well\n",
    "\n",
    "Whenever we need to generate a new instance of our weak learner, we'll have to call `get_weak_leaner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_weak_learner():\n",
    "    \"\"\"Return a new instance of our chosen weak learner\"\"\"\n",
    "    return DecisionTreeClassifier(max_depth=3, min_samples_leaf=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Start by completing the `Evaluator` class that we'll use to evaluate different ensemble methods.\n",
    "\n",
    "\n",
    "**Q3.2** [5 points] Complete the `evaluate_model` class to fit the model received as parameter and store the accuracy and running time.\n",
    "\n",
    "Since we don't have a validation set, you have to use StratifiedKFold (`self.k_fold`) to perform a 3-fold cross validation and store the mean accuracy over the 3 folds\n",
    "\n",
    "You can use the function `plot_metric` to show and compare different statistics of each model in a bar chart.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5e497072663b68825c534f3cb83d6ac",
     "grade": true,
     "grade_id": "a32",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\"\n",
    "        Test multiple model performance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        \"\"\" Initialize Evaluator\n",
    "        Args:\n",
    "            dataset: dataset containing Training and Test sets\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.execution_time = {}  # dictionary with key: model name, value: time taken to fit and score the model\n",
    "        self.scores = {}  # dictionary with key: model name, value: weighted average precision\n",
    "        self.score_name = 'Mean Accuracy'\n",
    "        self.k_fold = StratifiedKFold(3, shuffle=True, random_state=42)\n",
    "\n",
    "    def evaluate_model(self, model, name):\n",
    "        \"\"\" Fit the model using the training data and save the evaluation score on the test fold\n",
    "        Args:\n",
    "            model: classifier to evaluate\n",
    "            name: name of model\n",
    "        \"\"\"\n",
    "        start = time()\n",
    "        # Workspace 3.2\n",
    "        # TODO: Fit the model on 3 different folds and store the average accuracy in self.score[name]\n",
    "        # BEGIN \n",
    "        # code here\n",
    "        # END\n",
    "        self.execution_time[name] = time() - start\n",
    "\n",
    "    def print_results(self):\n",
    "        \"\"\"\n",
    "            print results for all models trained and tested.\n",
    "        \"\"\"\n",
    "        models_cross = pd.DataFrame({\n",
    "            'Model': list(self.scores.keys()),\n",
    "            self.score_name: list(self.scores.values()),\n",
    "            'Execution time': list(self.execution_time.values())})\n",
    "        print(models_cross.sort_values(by=self.score_name, ascending=False))\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        \"\"\"\n",
    "        Plot bar chart, one for each statistic (metric, score, running time)\n",
    "        \"\"\"\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        fig.set_figheight(6), fig.set_figwidth(18)\n",
    "        p = 0\n",
    "        for stats, name in zip([self.scores, self.execution_time],\n",
    "                               [self.score_name, \"Elapsed time\"]):\n",
    "            left = [i for i in range(len(stats))]\n",
    "            height = [stats[key] for key in stats]\n",
    "            tick_label = [key for key in stats]\n",
    "            axs[p].set_title(name)\n",
    "            axs[p].bar(left, height, tick_label=tick_label, width=0.5)\n",
    "            p += 1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Q3.3** [2 points] Test `Evaluator.evaluate_model` using our weak learner returned by `get_weak_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e55df1484e6cb9d364d7e02e090c3f04",
     "grade": true,
     "grade_id": "a33",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a handler for ensemble_test, use the created handler for fitting different models.\n",
    "ensemble_handler = Evaluator(house_prices)\n",
    "# Workspace 3.3\n",
    "# TODO: Initialize weak learner and evaluate it using evaluate_model\n",
    "# BEGIN \n",
    "# code here\n",
    "# END\n",
    "ensemble_handler.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bagging:**\n",
    "\n",
    "The first Ensemble technique we deal with is called _Bagging_ (Bootstrap AGGregatING).\n",
    "Bagging consists of training a number of weak learners using randomly sampled instances from our data (**with replacement**). We have to start\n",
    "by choosing the number of estimators we want to use. Then for each estimator, we sample a random subset of the data to fit the estimator.\n",
    "\n",
    "To compute the prediction, we sum the prediction probabilities of the estimators and return the label that has the highest\n",
    "accumulated probabilities.\n",
    "\n",
    "**Q3.4** [4 points] First, complete `sample_data` to return a random sample of size `sample_ratio* len(X_train)` of features and labels\n",
    "\n",
    "**Q3.5** [5 points] Complete `fit` by instantiating `n_estimators` of our weak leaner, each trained on random sample of the data\n",
    "\n",
    "**Q3.6** [4 points] Complete `predict` method to return the most likely label by combining different estimators predictions.\n",
    "\n",
    "Instead of the majority vote used in KNNClassifier, you should use `predict_proba` method of DecisionTreeClassifier.\n",
    "[See Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c2376b4c20857a33ccb2db008e40e65",
     "grade": true,
     "grade_id": "abagging",
     "locked": false,
     "points": 13,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BaggingEnsemble(object):\n",
    "\n",
    "    def __init__(self, n_estimators, sample_ratio=1.0):\n",
    "        \"\"\"\n",
    "        Initialize BaggingEnsemble\n",
    "        :param n_estimators: number of estimators/weak learner to use\n",
    "        :param sample_ratio: ratio of the training data to sample\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.estimators = []  # List used in fit method to store the trained estimators\n",
    "\n",
    "    def sample_data(self, X_train, y_train):\n",
    "        X_sample, y_sample = None, None\n",
    "        # Workspace 3.4\n",
    "        # TODO: sample random subset of size sample_ratio * len(X_train), sampling is with replacement (iid)\n",
    "        # BEGIN \n",
    "        # code here\n",
    "        # END\n",
    "        return X_sample, y_sample\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train the different estimators on sampled data using provided training samples\n",
    "        :param X_train: training samples, shape (num_samples, num_features)\n",
    "        :param y_train: training labels, shape (num_samples)\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        np.random.seed(42)  # Keep it to get consistent results across runs, you can change the seed value\n",
    "        self.estimators = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Workspace 3.5\n",
    "            # BEGIN \n",
    "            # code here\n",
    "            # END\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict the labels of test samples\n",
    "        :param X_test: array of shape (num_points, num_features)\n",
    "        :return: 1-d array of shape (num_points)\n",
    "        \"\"\"\n",
    "        predicted_proba = 0\n",
    "        answer = 0\n",
    "        # Workspace 3.6\n",
    "        # TODO: go through the trained estimators and accumulate their predicted_proba to get the mostly likely label\n",
    "        # BEGIN \n",
    "        # code here\n",
    "        # END\n",
    "        return answer\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell should run without errors\n",
    "ensemble_handler.evaluate_model(BaggingEnsemble(10, 0.9), 'Bagging')\n",
    "ensemble_handler.print_results()\n",
    "ensemble_handler.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8d68028ce57d0c522f8c7062c67cca9",
     "grade": false,
     "grade_id": "qforest",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random Forest\n",
    "\n",
    "Random Forest has an additional layer of randomness compared to Bagging: we also project the dataset into a lower dimensional subspace.\n",
    "The rest of the implementation should be similar if not exactly the same as Bagging. In addition to keeping track of the estimators, we also need to store the projection matrix associated with the estimator (since each estimator operates on a different subspace).\n",
    "\n",
    "First, we have to generate the random subspaces that we will project into. We do so by generating a random orthonormal basis of the subspace as follows:\n",
    "- Input space dimension n, subspace dimension m\n",
    "- Generate a random normal `G` matrix of shape (n,m): entries have mean 0 and standard deviation 1\n",
    "- Perform the reduced Q,R decomposition on `G` to get `Q` of shape (m,n)\n",
    "\n",
    "Then to project n features to m features, we right multiply by `Q`\n",
    "\n",
    "**Q3.7** [4 points] First, complete `random_projection` to return the random matrix `Q` of shape `input_dim, output_dim` whose columns are orthonormal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ec576dc8218abdb7de121d12bf83a32",
     "grade": true,
     "grade_id": "a37",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def random_projection(input_dim, output_dim):\n",
    "    \"\"\" Generate a matrix Q with orthonormal columns\n",
    "    Args:\n",
    "        input_dim: input dimension\n",
    "        output_dim: dimension of subspace to project into\n",
    "    Returns:\n",
    "        matrix of shape (input_dim, output_dim)\n",
    "    \"\"\"\n",
    "    assert input_dim >= output_dim\n",
    "    Q = None\n",
    "    # Workspace 3.7\n",
    "    # BEGIN \n",
    "    # code here\n",
    "    # END\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment to test\n",
    "# %run -i tests projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Q3.8** [4 points] Complete `fit` by building `n_estimators` of DecisionTreeClassifier, each trained on random projection of the data.\n",
    "Make sure to keep track of the projection matrix for each estimator to use them in the prediction step\n",
    "\n",
    "**Q3.9** [4 points] Complete `predict` method to return the most likely label by combining different estimators predictions. Instead of the majority vote used in KNNClassifier, you should use `predict_proba` method DecisionTreeClassifier:\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa0860d435396de74fe7f7614e6ffc3e",
     "grade": true,
     "grade_id": "aforest",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RandomForest(BaggingEnsemble):\n",
    "\n",
    "    def __init__(self, n_estimators, sample_ratio=1.0, features_ratio=1.0):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.features_ratio = features_ratio\n",
    "        self.estimators = []  # to store the estimator\n",
    "        self.projections = []  # to store the feature indices used by each estimator\n",
    "\n",
    "    def sample_data(self, X_train, y_train):\n",
    "        indices = np.random.choice(range(len(X_train)), size=int(self.sample_ratio * len(X_train)))\n",
    "        projection_matrix = random_projection(X_train.shape[1], int(X_train.shape[1] * self.features_ratio))\n",
    "        y_samples = y_train[indices]\n",
    "        X_samples = X_train[indices].dot(projection_matrix)\n",
    "        return X_samples, y_samples, projection_matrix\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # np.random.seed(42)  # keep to have consistent results across run, you can change the value\n",
    "        self.estimators = []  # to store the estimator\n",
    "        self.projections = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Workspace 3.8\n",
    "            # TODO: sample data with random subset of rows and features using sample_data\n",
    "            # Hint: keep track of the projections to use in predict\n",
    "            # BEGIN \n",
    "            # code here\n",
    "            # END\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predicted_proba = 0\n",
    "        answer = 0\n",
    "        # Workspace 3.9\n",
    "        # TODO: compute cumulative sum of predict proba from estimators and return the labels with highest likelihood\n",
    "        # BEGIN \n",
    "        # code here\n",
    "        # END\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell should run without errors\n",
    "ensemble_handler.evaluate_model(RandomForest(50, sample_ratio=0.7, features_ratio=0.1), 'RandomForest')\n",
    "ensemble_handler.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.10** [3 points] Add different ensemble methods to the handler (try different parameters), plot, show, and compare them.\n",
    "What's the best weighted average precision we can get? What's the best accuracy? Which ensemble method achieves each of them?\n",
    "You can also compare to our best decision tree found in Problem 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df44e39200612d66933b00ad37a5aab4",
     "grade": true,
     "grade_id": "a310",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create a handler for ensemble_test, use the created handler for fitting different models.\n",
    "ensemble_handler = Evaluator(house_prices)\n",
    "ensemble_handler.evaluate_model(get_weak_learner(), 'weak_learner')\n",
    "# Workspace 3.10.a\n",
    "# TODO Add multiple instances of the ensemble methods. Plot and compare their performance\n",
    "# You can also add best tree from problem 3\n",
    "# BEGIN \n",
    "# code here\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0571fb45830e1014dc459369c0be3e12",
     "grade": true,
     "grade_id": "a49b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "% BEGIN\n",
    "\n",
    "% YOUR ANSWER HERE\n",
    "\n",
    "% END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class AdaBoost (Bonus)\n",
    "\n",
    "There are different methods of boosting, but we'll focus in this problem on Adaptive Boosting (AdaBoost).\n",
    "The logic of AdaBoost is to \"push\" each new learner to give more importance to previously misclassified data. We present\n",
    "below the multiclass variant of AdaBoost [SAMME](https://web.stanford.edu/~hastie/Papers/samme.pdf). We denote $K$ the number of classes.\n",
    "\n",
    "AdaBosst is performed by increasing the weights of misclassified samples after each iteration:\n",
    "- Input: m samples $(X_i, y_i)_{i\\in [m]}$, number of boosting rounds $N$\n",
    "- Start with equal samples weights $W = (w_i), $ where   $w_i = \\frac{1}{\\texttt{n_samples}}$\n",
    "- at round j:\n",
    "    - Train estimator $h_j$ using current weights $W$\n",
    "    - Get the predicted $(\\hat{y}_i)$ on the training data using $h_j$\n",
    "    - Find the weighted error rate $\\epsilon_j$ using $W$: $\\epsilon_j=\\frac{\\sum_i w_i \\Delta(\\hat{y}_i, y_i)}{\\sum_i w_i}$\n",
    "    - Choose $\\alpha_j = \\log \\frac{1-\\epsilon_j}{\\epsilon_j} + \\log(K-1)$\n",
    "    - Update $W$ using: $w_i \\leftarrow w_i \\exp(\\alpha_j \\Delta(\\hat{y_i}, y_i)) $\n",
    "    - Normalize $W$ to have sum 1\n",
    "- Global estimator is $H = \\sum_j \\alpha_j h_j$,\n",
    "\n",
    "the $\\Delta$ function equals to 1 when the two argument are different, 0 otherwise.\n",
    "\n",
    "To understand how we implement $H$, imaging we have two classes, and we boosted for 3 rounds to get $(h_1, h_2, h_3)$,\n",
    "with weights $(\\alpha_1, \\alpha_2, \\alpha_3)$. When we want to predict the label of sample $x$, we get $(h_1(x), h_2(x), h_3(x)) = (0,1,0)$.\n",
    "\n",
    "In this case, label $0$ gets a weight $\\alpha_1+\\alpha_2$, while class $1$ get weight $\\alpha_2$. The predicted class is the one with\n",
    "the largest weight (1 if $\\alpha_2 > \\alpha_1 + \\alpha_3$, 0 otherwise)\n",
    "\n",
    "<br>\n",
    "\n",
    "**Q3.11.a (Bonus)** [2 pts] Complete `fit` by building `n_estimators` of DecisionTreeClassifier, each trained on the same data but with different samples weights as detailed in the algorithm. Keep track of $(\\alpha_i)$\n",
    "\n",
    "_Hint: our weak learner (DecisionTreeClassifier) can take an argument `sample_weight` when calling the `fit` method, you'll have to use it to provide the weights $W$_\n",
    " \n",
    "\n",
    "**Q3.11.b (Bonus)** [2pts] Complete `predict` method: it should handle multi-class labels, this is slighlty different from the binary case seen in the hands on)\n",
    "\n",
    "Note: Notice that if the estimator is consistent (0 error rate on the training set), AdaBoost $\\alpha_j$ are no longer defined. That's why this method requires a **weak** learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49baed5eba61452588afc3a8182292ae",
     "grade": true,
     "grade_id": "aboosting",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AdaBoost(BaggingEnsemble):\n",
    "\n",
    "    def __init__(self, n_estimators):\n",
    "        \"\"\"\n",
    "        :param n_estimators: number of estimators/ boosting rounds\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.num_classes = None\n",
    "        self.estimators = []\n",
    "        self.alphas = []\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.estimators = []\n",
    "        self.alphas = []\n",
    "        self.num_classes = np.unique(y_train).shape[0]  # K in the algorithm\n",
    "        weights = np.ones(len(X_train)) / len(X_train)  # W in the algorithm\n",
    "        # Workspace 4.10\n",
    "        # TODO: Implement Multiclass Adaboost and keep track of the alpha_j\n",
    "        # BEGIN \n",
    "        # code here\n",
    "        # END\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "        get the labels returned by the global estimator defined as H\n",
    "        the predicted label is the one that accumulates the largest sum of alphas\n",
    "        '''\n",
    "        # y_hat is one-hot encoding of the multi-class labels\n",
    "        answer = 0\n",
    "        # BEGIN \n",
    "        # code here\n",
    "        # END\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_handler.evaluate_model(AdaBoost(40), 'AdaBoost')\n",
    "ensemble_handler.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Comparison**\n",
    "\n",
    "- **(Bonus)**  3.11.c [1 point] Run the same comparison as in 3.10 including AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8788f50af1b95ae4fa486a4c543bd05e",
     "grade": true,
     "grade_id": "a411a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a handler for ensemble_test, use the created handler for fitting different models.\n",
    "ensemble_handler = Evaluator(house_prices)\n",
    "ensemble_handler.evaluate_model(get_weak_learner(), 'weak_learner')\n",
    "# Workspace 3.11.c\n",
    "# TODO Add multiple instances of the ensemble methods. Plot and compare their performance\n",
    "# BEGIN \n",
    "# code here\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d64296c1ef86f16f5f4c28fe086e2db9",
     "grade": true,
     "grade_id": "a411b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "% BEGIN\n",
    "\n",
    "% YOUR ANSWER HERE\n",
    "\n",
    "% END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
